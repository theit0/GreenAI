from pathlib import Path
from typing import Tuple
import streamlit as st
import torch
from PIL import Image
from torchvision import transforms
import torchvision.models as models

# ---------- Configuraci√≥n ----------
MODEL_PATH = Path(__file__).parent / "modelo.pth"
print(MODEL_PATH)
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# √çndice ‚Üí informaci√≥n de la clase
CLASS_INFO = {
    0: {
        "label": "cart√≥n",
        "bin_color": "azul",
        "symbol": "üì¶",
        "tip": "Dobla el cart√≥n para que ocupe menos espacio y col√≥calo limpio y seco en el contenedor azul."
    },
    1: {
        "label": "vidrio",
        "bin_color": "verde",
        "symbol": "üçæ",
        "tip": "Retira tapas o corchos y deposita el vidrio en el contenedor verde."
    },
    2: {
        "label": "metal",
        "bin_color": "amarillo",
        "symbol": "ü•´",
        "tip": "Enjuaga latas u otros metales ligeros y ll√©valos al contenedor amarillo."
    },
    3: {
        "label": "papel",
        "bin_color": "azul",
        "symbol": "üìÑ",
        "tip": "Papel limpio, sin grapas ni restos de comida, va en el contenedor azul."
    },
    4: {
        "label": "pl√°stico",
        "bin_color": "amarillo",
        "symbol": "üß¥",
        "tip": "Envases pl√°sticos limpios y secos se desechan en el contenedor amarillo."
    },
    5: {
        "label": "no reciclable",
        "bin_color": "gris",
        "symbol": "üóëÔ∏è",
        "tip": "Residuos mezclados u org√°nicos se depositan en el contenedor gris."
    },
}

# ---------- Construcci√≥n de la arquitectura ----------
def build_model(num_classes: int = 6):
    """Devuelve la arquitectura exacta usada en entrenamiento."""
    model = models.resnet18(weights=None)
    model.fc = torch.nn.Linear(model.fc.in_features, num_classes)
    return model

# ---------- Carga del modelo (cacheada por Streamlit) ----------
@st.cache_resource(show_spinner=False)
def load_model():
    state_dict = torch.load(MODEL_PATH, map_location=DEVICE)
    model = build_model()
    model.load_state_dict(state_dict) # aqu√≠ cargamos pesos
    model.to(DEVICE)
    model.eval()
    return model

# ---------- Preprocesamiento igual al entrenamiento ----------
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    # normaliza con las medias/desvs que usaste para entrenar
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225]),
])

# ---------- Predicci√≥n ----------
def predict(image: Image.Image, topk: int | None = None):
    """
    Devuelve una lista ordenada de (idx, prob) para todas las clases
    o solo las `topk` primeras si se indica.
    Prob se da en porcentaje (0-100).
    """
    if image.mode != "RGB":
        image = image.convert("RGB")

    model = load_model()
    img_tensor = preprocess(image).unsqueeze(0).to(DEVICE)

    with torch.no_grad():
        logits = model(img_tensor)
        probs = torch.softmax(logits, dim=1).squeeze(0).cpu()

    if topk is None:
        topk = probs.size(0)

    top_prob, top_idx = probs.topk(topk)          # ya vienen ordenadas
    return [(idx.item(), prob.item() * 100) for idx, prob in zip(top_idx, top_prob)]